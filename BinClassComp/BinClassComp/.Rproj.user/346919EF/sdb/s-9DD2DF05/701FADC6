{
    "collab_server" : "",
    "contents" : "#' Get data\n#'\n#' Get data of Sql Server\n#'\n#' @param name_object is name of oject\n#'\n#' @param query is query text\n#'\n#' @param connectionStringDataMine is a connection string\n#'\n#' @return list of data and y_name\n#'\n#' @export\nbmi3<-function(x){\n\tb<-x^2\n\treturn(b)\n}\n\n\n\nlibrary(RODBC)\nlibrary(caret)\nlibrary(InformationValue)\nlibrary(glmnet)\nlibrary(pROC)\nlibrary(randomForest)\nlibrary(car)\nlibrary(RColorBrewer)\nlibrary(xgboost)\nlibrary(ROSE)\n\nscriptPath <- function() {\n\tgetSrcDirectory(scriptPath);\n}\n\n#' Get data\n#'\n#' Get data of Sql Server\n#' @param y_name is name of outcome\n#' @param query is query text\n#' @param connectionStringDataMine is a connection string\n#' @return list of data and y_name\n#' @export\nget_data<-function(y_name,query,connection_string)\n{\n\tdbhandle <- odbcDriverConnect(connection_string)\n\tdata<-sqlQuery(dbhandle,query)\n\ton.exit(odbcClose(dbhandle))\n\treturn(list(y_name=y_name,data=data))\n}\n\n\n#' Z-test\n#'\n#' #' Z-test for binary features\n#' @param x1 is first vecot\n#' @param x2 is second vector\n#' @return value of statisic\n#' @export\nz_test<-function(x1,x2)\n{\n\tn1<-length(x1)\n\tn2<-length(x2)\n\tm1<-sum(x1)\n\tm2<-sum(x2)\n\tif((m1+m2)!=0 & (m1+m2)!=(n1+n2) & n1!=0 & n2!=0)\n\t{\n\t\tzd<-((m1+m2)/(n1+n2))*((n1+n2-m1-m2)/(n1+n2))*(1/n1+1/n2)\n\t\tz<-(m1/n1+1/(2*n1)-m2/n2-1/(2*n2))/sqrt(zd)\n\t\tp_value<-pnorm(z,mean = 0, sd = 1,lower.tail=FALSE)\n\t}\n\telse\n\t{\n\t\tz<-NA\n\t\tp_value<-1\n\t}\n\n\treturn(p_value)\n}\n\n#' Wilcoxon test\n#'\n#' wilcoxon test for numeric vectors\n#' @param x1 is first vecot\n#' @param x2 is second vector\n#' @return value of statisic\n#' @export\nw_test<-function(x1,x2)\n{\n\tw<-wilcox.test(x1,x2)\n\tp_value<-w$p.value\n\treturn(p_value)\n}\n\n#' Bartletta test\n#'\n#' Bartletta test for multicollinearity\n#' @param x is matrix of features\n#' @param alpha is significant level\n#' @return value of statisic\n#' @export\ntestBartlett<-function(x,alpha)\n{\n\tif(ncol(x)<2)\n\t{\n\t\treturn(FALSE)\n\t}\n\tm<-ncol(x)\n\tN<-nrow(x)\n\tR<-cor(x)\n\tdetR<-(det(R))\n\tif( !is.na(detR) ){\n\t\tB<- -(N-1-(1/6)*(2*m+5))*log(abs(det(R)))\n\t\tpValue <- pchisq(B, df=m*(m-1)/2, lower.tail = FALSE)\n\t\tresult <- ifelse(pValue > alpha, TRUE, FALSE)\n\t\treturn(result)\n\t}\n\treturn(FALSE)\n}\n\n#' Features selection\n#'\n#' Features selection for classification\n#' @param env is data environment\n#' @param alpha is significant level\n#' @return significant columns\n#' @export\nsignificant_features<-function(env,alpha = 0.1)\n{\n\tsig_colums<-c(env$y_number)\n\tdata_study_0<-env$data_study[which(env$data_study[,env$y_number] == 0),]\n\tdata_study_1<-env$data_study[which(env$data_study[,env$y_number] == 1),]\n\tfor(i in (env$y_number + 1):ncol(env$data_study))\n\t{\n\t\tif(typeof(env$data_study[,i]) == \"double\")\n\t\t{\n\t\t\tif(length(unique(env$data_study[,i])) == 2)\n\t\t\t{\n\t\t\t\tp_value<-z_test(data_study_1[,i], data_study_0[,i])\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t#means\n\t\t\t\tp_value<-w_test(data_study_1[,i], data_study_0[,i])\n\t\t\t\t#variance\n\t\t\t\tif (p_value >= alpha/2 & p_value <= (1-alpha/2))\n\t\t\t\t{\n\t\t\t\t\tp_value<-mood.test(data_study_1[,i], data_study_0[,i])$p.value\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(!is.nan(p_value)) {\n\t\t\t\tif (p_value <= alpha/2 | p_value >= (1-alpha/2)){\n\t\t\t\t\tsig_colums<-c(sig_colums,i)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse{\n\t\t\tvalues = factor(env$data_study[,i])\n\t\t\tpValue = chisq.test(values, env$data_study[,env$y_number])$p.value\n\t\t\tif(!is.nan(pValue)) {\n\t\t\t\tif (pValue <= alpha/2){\n\t\t\t\t\tsig_colums<-c(sig_colums,i)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tenv$data_study<-env$data_study[,sig_colums]\n\tenv$data_test<-env$data_test[,sig_colums]\n\treturn(sig_colums)\n}\n\n#' Multicollinearity deletion\n#'\n#' Multicollinearity deletion\n#' @param env is data environment\n#' @param method is choice of vif or bartlett\n#' @param alpha is significant level\n#' @param vif_bound is bound for vif\n#' @return remaining features\n#' @export\nmulti_features<-function(env, method = 'bartlett', alpha = 0.05, vif_bound = 4)\n{\n\tif(ncol(env$data_study)<=2)\n\t{\n\t\treturn(seq(1:ncol(env$data_study)))\n\t}\n\n\tsig_colums<-c(env$y_number)\n\tis_numeric_columns<-apply(env$data_study,2,is.numeric)\n\tsig_colums<-c(sig_colums,which( colnames(env$data_study)== names(is_numeric_columns[which(is_numeric_columns == FALSE)])))\n\n\tif(method == 'vif')\n\t{\n\t\tev<-names(env$data_study[,-env$y_number])\n\t\tvif_list<-NULL\n\t\twhile((is.null(vif_list)|length(vif_list[vif_list>=vif_bound])>0) & length(ev)>1)\n\t\t{\n\t\t\tvif_list<-sapply(ev,function(e){\n\t\t\t\tr<-summary(lm(as.formula(paste(e,\"~\",paste(ev[ev!=e],collapse=\"+\"))),data=env$data_study, family = binomial()))$r.squared\n\t\t\t\treturn(ifelse(r==1,100000,sqrt(1/(1-r))))\n\t\t\t})\n\t\t\tev<-ev[-(which.max(vif_list))]\n\t\t}\n\t\tsig_colums<-c(sig_colums, which(colnames(env$data_study) %in% ev))\n\t}\n\tout_colums<-c()\n\tif(method == 'bartlett')\n\t{\n\t\twhile(ncol(env$data_study[,-c(sig_colums,out_colums),drop=FALSE]) >= 2 & testBartlett(env$data_study[,-c(sig_colums,out_colums),drop=FALSE],alpha = alpha)==FALSE  )\n\t\t{\n\t\t\tR<-cor(env$data_study[,-c(sig_colums,out_colums)])\n\t\t\tRobr<-solve(R,tol = 1e-40)\n\t\t\tRm<-c()\n\t\t\tfor( j in 1:ncol(env$data_study[,-c(sig_colums,out_colums)]))\n\t\t\t{\n\t\t\t\tRm<-c(Rm,sqrt(1-1/Robr[j,j]))\n\t\t\t}\n\t\t\tout_colums<-c(out_colums,which(colnames(env$data_study) == names(env$data_study[,-c(sig_colums,out_colums)])[(which.max(Rm))]))\n\t\t}\n\t\tsig_colums<-seq(1,ncol(env$data_study))\n\t\tsig_colums<-c(sig_colums[!sig_colums %in% out_colums])\n\t}\n\tenv$data_study<-env$data_study[,sig_colums]\n\tenv$data_test<-env$data_test[,sig_colums]\n\treturn(sig_colums)\n}\n\n#' Box-Cox Transformation\n#'\n#' Box-Cox Transformation\n#' @param feature is feature for transformation\n#' @param lamda is conversion parameter\n#' @return transform feature\n#' @export\nbox_cox<-function(feature,lamda)\n{\n\tif(lamda!=0)\n\t{\n\t\tfeature<-((feature)^lamda-1)/lamda\n\t}\n\telse\n\t{\n\t\tfeature<-log(feature)\n\t}\n\treturn(feature)\n}\n\n#' Features selection by AUC\n#'\n#' Features selection by AUC\n#' @param env is data environment\n#' @param alg is algoritm of forward/backwards selection\n#' @return significant columns\n#' @export\nget_feature_step<-function(env,alg='b')\n{\n\tmodel='glm'\n\tfeature_number<-seq(env$y_number+1,ncol(env$data_study))\n\tif(alg==\"f\")\n\t{\n\t\tstep<-TRUE\n\t\tauc_best<-0\n\t\tauc_best_number<-c()\n\t\twhile(step)\n\t\t{\n\t\t\tauc<-sapply(feature_number,function(t){\n\t\t\t\tmodel_res<-get_model(env$data_study[,c(env$y_number,auc_best_number,t)],model)\n\t\t\t\tpredict<-get_prediction(model_res,env$data_study[,c(auc_best_number,t),drop=FALSE],model)\n\t\t\t\tauc<-roc.curve(env$data_study[,env$y_number],predict,plotit = F)$auc\n\t\t\t\treturn(auc)\n\t\t\t})\n\t\t\tauc_max<-max(auc)\n\t\t\tif (auc_best<=auc_max)\n\t\t\t{\n\t\t\t\tauc_best<-auc_max\n\t\t\t\tauc_best_number<-c(auc_best_number,feature_number[which.max(auc)])\n\t\t\t\tfeature_number<-feature_number[-which.max(auc)]\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstep<-FALSE\n\t\t\t}\n\t\t}\n\t\tfeature_number<-auc_best_number\n\t}\n\tif(alg==\"b\")\n\t{\n\t\tstep<-TRUE\n\t\tmodel_res<-get_model(env$data_study,model)\n\t\tpredict<-get_prediction(model_res,env$data_study,model)\n\t\tauc_all<-roc.curve(env$data_study[,env$y_number],predict,plotit = F)$auc\n\t\tfeature_del<-c()\n\t\twhile(step & length(feature_number)>1)\n\t\t{\n\t\t\tauc<-sapply(feature_number,function(t)\n\t\t\t{\n\t\t\t\tmodel_res<-get_model(env$data_study[,-c(t,feature_del)],model)\n\t\t\t\tpredict<-get_prediction(model_res,env$data_study[,-c(t,feature_del)],model)\n\t\t\t\tauc<-roc.curve(env$data_study[,env$y_number],predict,plotit = F)$auc\n\t\t\t\treturn(auc)\n\t\t\t})\n\t\t\tauc_max<-max(auc)\n\t\t\tif (auc_all<=auc_max)\n\t\t\t{\n\t\t\t\tfeature_del<-c(feature_del,feature_number[which.max(auc)])\n\t\t\t\tfeature_number<-feature_number[-which.max(auc)]\n\t\t\t\tauc_all<-auc_max\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstep<-FALSE\n\t\t\t}\n\t\t}\n\t}\n\tenv$data_study<-env$data_study[,c(env$y_number,feature_number)]\n\tenv$data_test<-env$data_test[,c(env$y_number,feature_number)]\n}\n\n#' Prepare data by box_cox\n#'\n#' Prepare data by box_cox transformation\n#' @param env is data environment\n#' @param lamda range for lamda\n#' @return data frame with information about lamda\n#' @export\nprepare_box_cox<-function(env,lamda=seq(-4,4,0.01))\n{\n\tmodel<-'glm'\n\tnormalization(env)\n\tbc_info<-NULL\n\ttmp_study<-env$data_study\n\tfor(i in (env$y_number+1):ncol(env$data_study))\n\t{\n\t\tauc<-sapply(lamda,function(t){\n\t\t\ttmp_study[,i]<-box_cox(env$data_study[,i],t)\n\t\t\tmodel_res<-get_model(tmp_study[,c(env$y_number,i)],model)\n\t\t\tpredict<-get_prediction(model_res,tmp_study[,i,drop=FALSE],model)\n\t\t\tauc<- roc.curve(tmp_study[,env$y_number],predict,plotit = F)$auc\n\t\t\treturn(auc)\n\t\t})\n\t\tlamda_best<-lamda[which.max(auc)]\n\n\t\tbc_info<-rbind(bc_info,c(names(env$data_study)[i],lamda_best))\n\t\tenv$data_study[,i]<-box_cox(env$data_study[,i],lamda_best)\n\t\tif(is.null(env$data_test)==FALSE)\n\t\t{\n\t\t\tenv$data_test[,i] <-box_cox(env$data_test[,i],lamda_best)\n\t\t}\n\t}\n\tbc_info<-as.data.frame(bc_info)\n\tnames(bc_info)<-c(\"names\",\"lamda\")\n\tbc_info[,1]<-as.character(paste(bc_info[,1]))\n\tbc_info[,2]<-as.numeric(paste(bc_info[,2]))\n\treturn(bc_info=bc_info)\n}\n\n#' Replace anomalies\n#'\n#' Replace anomalies\n#' @param env is data environment\n#' @param k is coefficient for box plot\n#' @param max_part_outlier is max part outlier for replacement\n#' @param step step for change k\n#' @return data frame with change information\n#' @export\nreplace_anomalies<-function(env, k=1.5, max_part_outlier=0.2, step=0.5)\n{\n\ti<-env$y_number+1\n\tnumbers_outlier<-c()\n\tmax_count_outlier<-ceiling(max_part_outlier*nrow(env$data_study))\n\n\trepeat\n\t{\n\t\txL<-log(env$data_study[,i]+abs(min(env$data_study[,i]))+1)\n\t\tQ1<-quantile(xL)[[2]]\n\t\tQ3<-quantile(xL)[[4]]\n\t\tif(Q1!=Q3)\n\t\t{\n\t\t\tx1<-Q1-k*(Q3-Q1)\n\t\t\tx2<-Q3+k*(Q3-Q1)\n\n\t\t\toutlier<-which( xL<x1 | xL>x2 )\n\t\t\tnumbers_outlier<-unique(c(numbers_outlier,outlier))\n\t\t\tif(length(numbers_outlier)>max_count_outlier)\n\t\t\t{\n\t\t\t\ti<-env$y_number+1\n\t\t\t\tnumbers_outlier<-c()\n\t\t\t\tk<-k+step\n\t\t\t}\n\t\t}\n\t\tif(i==ncol(env$data_study))\n\t\t{\n\t\t\tbreak\n\t\t}\n\t\ti<-i+1\n\t}\n\tmax_min<-data.frame(\"names\"=character(),\"max\"=numeric(),\"min\"=numeric())\n\tif(length(numbers_outlier)>0)\n\t{\n\t\tx_without_outlier<-env$data_study[-numbers_outlier,]\n\t\tfor(i in (env$y_number + 1):ncol(env$data_study))\n\t\t{\n\t\t\tmax<-max(x_without_outlier[,i])\n\t\t\tmin<-min(x_without_outlier[,i])\n\t\t\tenv$data_study[env$data_study[,i]>max,i]<-max\n\t\t\tenv$data_study[env$data_study[,i]<min,i]<-min\n\t\t\tif(is.null(env$data_test)==FALSE)\n\t\t\t{\n\t\t\t\tenv$data_test[env$data_test[,i]>max,i]<-max\n\t\t\t\tenv$data_test[env$data_test[,i]<min,i]<-min\n\t\t\t}\n\t\t\tmax_min<-rbind(max_min,data.frame(\"names\"=names(env$data_study)[i],\"max\"=max,\"min\"=min))\n\t\t}\n\t}\n\tmax_min$names<-as.character(paste(max_min$names))\n\treturn(max_min=max_min)\n}\n\n#' Standartization of data\n#'\n#' Standartization of data\n#' @param env is data environment\n#' @export\nstandartization<-function(env)\n{\n\tenv$data_study[,-env$y_number] <- as.data.frame(scale(env$data_study[,-env$y_number,drop=FALSE]))\n\tenv$data_study[is.na(env$data_study)]<-0\n\tif( !is.null(env$data_test))\n\t{\n\t\tenv$data_test[,-env$y_number] <- as.data.frame(scale(env$data_test[,-env$y_number,drop=FALSE]))\n\t\tenv$data_test[is.na(env$data_test)]<-0\n\t}\n}\n\n#' Normalization of data\n#'\n#' Normalization of data\n#' @param env is data environment\n#' @export\nnormalization<-function(env)\n{\n\tenv$data_study[,-env$y_number] <- do.call(cbind, apply(env$data_study[,-env$y_number,drop=FALSE],2,function(x){list(x+abs(min(x))+1)}))\n\tif( !is.null(env$data_test))\n\t{\n\t\tenv$data_test[,-env$y_number] <- do.call(cbind, apply(env$data_test[,-env$y_number,drop=FALSE],2,function(x){list(x+abs(min(x))+1)}))\n\t}\n}\n\n#' Prepare data\n#'\n#' Prepare data study and test\n#' @param data_study data study\n#' @param data_test data test\n#' @param y_name is a name of oucome colum\n#' @param feature_select logical value is it necessary feature select\n#' @param stand logical value is it necessary feature standardization\n#' @param multi is logical value delete multicollinearity\n#' @param anomalies is logical value using of method for optimal boarding\n#' @param box_cox is logical value replace anomalies\n#' @param feature_step  is logical value select features by AUC\n#' @return list\n#' @export\nprepare_study<-function(data_study, data_test = NULL,y_name = 'EndCat',\n\t\t\t\t\t\t\t\t\t\t\t\tfeature_select = FALSE,multi=TRUE,anomalies=TRUE,box_cox=FALSE,stand=FALSE,feature_step=FALSE)\n{\n\tif(is.null(data_study) | nrow(data_study) == nrow(data_study[data_study$y == 1,]))\n\t{\n\t\tprint('Incorect data study')\n\t\treturn(NULL)\n\t}\n\t#reNaming\n\tenv<-new.env()\n\tenv$y<-\"y\"\n\tcolumns_numbers<-seq(which( colnames(data_study) == y_name),ncol(data_study))\n\n\tcolnames(data_study)[which( colnames(data_study) == y_name)] <- env$y\n\tenv$data_study <- data_study[,columns_numbers]\n\n\tif( !is.null(data_test))\n\t{\n\t\tcolnames(data_test)[which( colnames(data_test) == y_name)] <- env$y\n\t\tenv$data_test <- data_test[,columns_numbers]\n\t}\n\telse\n\t{\n\t\tenv$data_test <- NULL\n\t}\n\tenv$y_number<-which( colnames(env$data_study) == env$y)\n\n\tif(feature_select)\n\t{\n\t\tcolumns_numbers<-significant_features(env)\n\t\tif(length(columns_numbers)<2)\n\t\t{\n\t\t\tprint(paste('Not enough feature = ', columns_numbers, 'feature_select = ', feature_select))\n\t\t\treturn( NULL )\n\t\t}\n\t}\n\tif(multi)\n\t{\n\t\tcolumns_numbers<-multi_features(env)\n\t\tif(length(columns_numbers)<2)\n\t\t{\n\t\t\tprint(paste('Not enough feature = ', columns_numbers, 'feature_select = ', feature_select))\n\t\t\treturn( NULL )\n\t\t}\n\t}\n\tmax_min_info<-NULL\n\tif(anomalies)\n\t{\n\t\tmax_min_info<-replace_anomalies(env)\n\t}\n\tlamda_info<-NULL\n\tif(box_cox)\n\t{\n\t\tlamda_info<-prepare_box_cox(env)\n\t\tprint(lamda_info)\n\t}\n\tif(feature_step)\n\t{\n\t\tcolumns_numbers<-get_feature_step(env)\n\t\tif(length(columns_numbers)<2)\n\t\t{\n\t\t\tprint(paste('Not enough feature = ', columns_numbers, 'feature_select = ', feature_select))\n\t\t\treturn( NULL )\n\t\t}\n\t}\n\tif(stand)\n\t{\n\t\tstandartization(env)\n\t}\n\treturn(list(data_study = env$data_study,\n\t\t\t\t\t\t\tdata_test  = env$data_test,\n\t\t\t\t\t\t\tprepare_info = list(feature_select = feature_select,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmulti=multi,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tanomalies=anomalies,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbox_cox=box_cox,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstand = stand,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfeature_step=feature_step,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlamda_info=lamda_info,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmax_min_info=max_min_info,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsignificant_features=names(env$data_study)[-1],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ty_name = y_name,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ty = env$y)\n\t))\n}\n\n#' Get model\n#'\n#' Comparison of several models\n#' @param data_study data study\n#' @param model is name of model\n#' @param y_name is a name of oucome colum\n#' @return object\n#' @export\nget_model<-function(data_study = NULL, model='glm', y_name = 'y')\n{\n\tpredictorsNames <- names(data_study)[!names(data_study) %in% c(y_name)]\n\t#get_feature_step\n\tif (model =='glmnetCV')\n\t{\n\t\tobjModel<-cv.glmnet(x = as.matrix(data_study[,predictorsNames,drop=FALSE]), y = data_study[,y_name], alpha = 1\n\t\t\t\t\t\t\t\t\t\t\t\t, family = \"binomial\", type.measure = \"auc\")\n\t}\n\tif (model == 'glm')\n\t{\n\t\tobjModel<-glm(as.formula(paste(\"y~\",paste(predictorsNames,collapse=\"+\"))),data = data_study, family = binomial())\n\t}\n\tif(model=='gbm')\n\t{\n\t\tdata_study$y<-ifelse(data_study$y==1,'Return','No')\n\n\t\tobjControl <- trainControl(method='repeatedcv', repeats = 5,number=5,returnResamp='none',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t summaryFunction = twoClassSummary,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t classProbs = TRUE,verboseIter = FALSE)\n\n\t\tobjModel <- train(data_study[,predictorsNames,drop=FALSE], data_study[,y_name],\n\t\t\t\t\t\t\t\t\t\t\tmethod = model,\n\t\t\t\t\t\t\t\t\t\t\ttrControl = objControl,\n\t\t\t\t\t\t\t\t\t\t\tmetric = \"ROC\",\n\t\t\t\t\t\t\t\t\t\t\tpreProc = c(\"center\", \"scale\")\n\t\t\t\t\t\t\t\t\t\t\t#,tuneGrid = expand.grid(alpha = 1, lambda = seq(0,1,by = 0.001))\n\t\t)\n\t}\n\tif(model=='rf')\n\t{\n\n\t\tbestmtry <- tuneRF(data_study[,predictorsNames], as.factor(data_study[,y_name]),  stepFactor=2, improve=0.05, ntree=500)\n\t\tdata_study[,y_name]<-as.factor(make.names(data_study[,y_name]))\n\n\t\tobjControl <- trainControl(method = \"cv\", classProbs = TRUE, summaryFunction = twoClassSummary, number = 5)\n\n\t\tobjModel<- train(as.formula(paste(y_name,\"~\",paste(predictorsNames,collapse=\"+\"))), data = data_study,\n\t\t\t\t\t\t\t\t\t\t method = model,mpty=bestmtry[which.min(bestmtry[,2]),1],# tuneGrid = rfGrid,\n\t\t\t\t\t\t\t\t\t\t metric = \"ROC\", trControl = objControl, importance = TRUE)\n\t}\n\tif(model=='rpart')\n\t{\n\t\tdata_study[,y_name]<-make.names(as.factor(data_study[,y_name]))\n\t\tobjControl <- trainControl(method='repeatedcv', number=5,returnResamp='none',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t repeats =20, summaryFunction = twoClassSummary,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t classProbs = TRUE,verboseIter = FALSE)\n\t\tobjModel<- train(data_study[,predictorsNames,drop=FALSE], data_study[,y_name],\n\t\t\t\t\t\t\t\t\t\t method = model,\n\t\t\t\t\t\t\t\t\t\t metric = \"ROC\", trControl = objControl)\n\t}\n\treturn(objModel)\n}\n\n#' Get prediction\n#'\n#' Prediction function for all methods\n#' @param objModel model object\n#' @param data data for preidction\n#' @param model is name of model\n#' @param y_name is a name of oucome colum\n#' @return vecotr of prediction values\n#' @export\nget_prediction<-function(objModel, data = NULL, model='glm', y_name = 'y')\n{\n\tpredictorsNames <- names(data)[!names(data) %in% y_name]\n\tif(model=='glmnetCV')\n\t{\n\t\tpredictions <- predict(object = objModel, as.matrix(data[,predictorsNames,drop=FALSE]), s = \"lambda.min\", type = \"response\")[,1]\n\t}\n\tif(model=='glm')\n\t{\n\t\tpredictions<-1/(1+exp(-predict.glm(objModel ,data[,predictorsNames,drop=FALSE])))\n\t}\n\tif(model=='gbm')\n\t{\n\t\tpredictions <- predict(object=objModel, data[,predictorsNames,drop=FALSE], type='prob')$Return\n\t}\n\tif(model=='rf')\n\t{\n\t\tpredictions <- predict(object=objModel, data[,predictorsNames,drop=FALSE], type='prob')$X1\n\t}\n\tif(model=='rpart')\n\t{\n\t\tpredictions <- predict(object=objModel, data[,predictorsNames,drop=FALSE], type='prob')$X1\n\t}\n\treturn(unname(predictions))\n}\n\n#' Get quality classification\n#'\n#' Get quality classification\n#' @param y true values for response\n#' @param est estimation values for response\n#' @param optimal_border using of method for optimal boarding\n#' @param plot_roc is logical value for plot roc\n#' @return list of quality metrics\n#' @export\nget_quality<-function(y,est, optimal_border = 0.5, plot_roc = FALSE)\n{\n\test<-data.frame(\"est\" = est,\"y\" = y)\n\tN<-nrow(est)\n\tTP<-nrow(est[est$est >= optimal_border & est$y==1,])\n\tTN<-nrow(est[est$est < optimal_border & est$y==0,])\n\tAP<-nrow(est[est$y==1,])\n\tAN<-nrow(est[est$y==0,])\n\n\tFP<-nrow(est[est$est >= optimal_border & est$y==0,])\n\tFN<-nrow(est[est$est < optimal_border & est$y==1,])\n\n\taccuracy<-(TP+TN)/N\n\tprecision<-ifelse((TP+AN-TN)==0,0,TP/(TP+AN-TN))\n\trecall<-ifelse(AP==0,0,TP/AP)\n\tfmesure<-ifelse((precision+recall)==0,0,2*(precision*recall)/(precision+recall))\n\troc_obj<-roc(est$y,est$est,quiet = TRUE)\n\tplot_res <- 0\n\tif(plot_roc){\n\t\tplot_res = plot(roc_obj)\n\t}\n\test<-est[order(est$est,decreasing=TRUE),]\n\tpartTop<-sum(est$y[1:AP])/AP\n\n\treturn(list(\"Optimal_border\" = optimal_border,\n\t\t\t\t\t\t\t\"AP\" = AP,\n\t\t\t\t\t\t\t\"AN\" = AN,\n\t\t\t\t\t\t\t\"TP\" = TP,\n\t\t\t\t\t\t\t\"TN\" = TN,\n\t\t\t\t\t\t\t\"FP\" = FP,\n\t\t\t\t\t\t\t\"FN\" = FN,\n\t\t\t\t\t\t\t'Auc'= roc.curve(est$y,est$est,plotit = F)$auc,\n\t\t\t\t\t\t\t'F_measure' = fmesure,\n\t\t\t\t\t\t\t'PartTop' = partTop,\n\t\t\t\t\t\t\t'Plot_auc' = plot_res))\n}\n\n#' Cross-Validation\n#'\n#' get quality cross-validation\n#' @param xy data study\n#' @param n_folds folds number\n#' @param models is name of model\n#' @param optimal_border using of method for optimal boarding\n#' @param y_name is a name of oucome colum\n#' @return result data.frame\n#' @export\nget_quality_cv<- function(xy, n_folds=10, model, y_name = 'y',optimal_border = FALSE)\n{\n\tcolumns_numbers<-seq(which( colnames(xy) == y_name),ncol(xy))\n\txy<-xy[sample(nrow(xy)),columns_numbers]\n\tif(n_folds>1)\n\t{\n\t\txy_0<-xy[xy$y==0,]\n\t\txy_1<-xy[xy$y==1,]\n\t\tfolds_i_0 <- sample(rep(1:n_folds, length.out =nrow(xy_0)))\n\t\tfolds_i_1 <- sample(rep(1:n_folds, length.out =nrow(xy_1)))\n\t\tquality<-data.frame()\n\t\tfor(j in 1:n_folds)\n\t\t{\n\t\t\tstudy_xy <- rbind(xy_0[-which(folds_i_0 == j), ],xy_1[-which(folds_i_1 == j), ])\n\t\t\ttest_xy <-  rbind(xy_0[ which(folds_i_0 == j), ],xy_1[ which(folds_i_1 == j), ])\n\t\t\tmodel_xy<-get_model(study_xy,model)\n\t\t\tpredict_xy<-get_prediction(model_xy,test_xy,model)\n\t\t\tquality_xy<-get_quality(test_xy[,y_name],predict_xy,optimal_border,plot_roc = FALSE)\n\t\t\tmodel_info<-get_model_info(model_xy,model)\n\t\t\tquality_xy<-c(quality_xy,count_features_in_model=nrow(model_info[model_info[,2] < 0 | model_info[,2] > 0, ]))\n\n\t\t\tquality<-rbind(quality,quality_xy)\n\t\t}\n\t\tquality<-as.data.frame(as.list(apply(quality,2,\"mean\")))\n\t}\n\tif(n_folds==1)\n\t{\n\t\tmodel_xy<-get_model(xy,model)\n\t\tpredict_xy<-get_prediction(model_xy,xy,model)\n\t\tquality_xy<-get_quality(xy[,y_name],predict_xy,optimal_border,plot_roc = FALSE)\n\t\tmodel_info<-get_model_info(model_xy,model)\n\t\tquality<-as.data.frame(c(quality_xy,count_features_in_model=nrow(model_info[model_info[,2] < 0 | model_info[,2] > 0, ])))\n\t}\n\tif(n_folds<1)\n\t{\n\t\treturn(NULL)\n\t}\n\n\n\treturn(quality)\n}\n\n#' model info\n#'\n#' Get model informatoin\n#' @param obj_model model\n#' @param model model name\n#' @return result data.frame\n#' @export\nget_model_info<-function(obj_model,model)\n{\n\tif(model =='glmnetCV')\n\t{\n\t\tcoef<-as.data.frame(as.matrix(coef(obj_model)))\n\t\tmodel_info<-cbind(row.names(coef),coef)\n\t\tnames(model_info)<-c(\"Evidence\",\"Coef\")\n\t}\n\tif (model == 'glm')\n\t{\n\t\tcoef<-as.data.frame(coef(obj_model))\n\t\tmodel_info<-cbind(row.names(coef),coef)\n\t\tnames(model_info)<-c(\"Evidence\",\"Coef\")\n\t}\n\t#carret\n\tif(model=='gbm')\n\t{\n\t\tmodel_info<-summary(obj_model)\n\t\tnames(model_info)<-c(\"Evidence\",\"Influence\")\n\n\t}\n\tif(model=='rf')\n\t{\n\t\tinf<-varImp(object=obj_model)$importance\n\t\tmodel_info<-cbind(row.names(inf),inf)[-3]\n\t\tnames(model_info)<-c(\"Evidence\",\"Importance\")\n\t}\n\tif(model=='rpart')\n\t{\n\t\tinf<-varImp(object=obj_model)$importance\n\t\tmodel_info<-cbind(row.names(inf),inf)[-3]\n\t\tnames(model_info)<-c(\"Evidence\",\"Importance\")\n\t}\n\trow.names(model_info)<-NULL\n\treturn(model_info)\n}\n\n#' Comparison classifications\n#'\n#' Comparison of several models\n#' @param data_study data study\n#' @param data_test data test\n#' @param models is name of models\n#' @param y_name is a name of oucome colum\n#' @param cv_n_folds folds number\n#' @param is_optimal_border  using of method for optimal boarding\n#' @param stand logical vector is it necessary feature standardization\n#' @param multi is logical vector delete multicollinearity\n#' @param anomalies is logical vector using of method for optimal boarding\n#' @param box_cox is logical vector replace anomalies\n#' @param feature_step  is logical vector select features by AUC\n#' @param feature_select is logical vector is it necessary feature select\n#' @return list\n#' @export\ncompare_classifications<-function(data_study, data_test = NULL, y_name = 'y', models=c(\"gbm\",\"glm\"),is_optimal_border=TRUE,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfeature_select=c(FALSE),multi=c(TRUE,FALSE),anomalies=c(TRUE,FALSE),box_cox=c(FALSE),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfeature_step=c(TRUE,FALSE),stand=TRUE,n_folds=10,plot_test=FALSE)\n{\n\toptions(digits=5)\n\toptions(scipen = 999)\n\n\tname_list<-c()\n\tmodel_info_all<-data.frame(\"Evidence\"=character())\n\tquality_test_all<-data.frame()\n\tquality_cv_all<-data.frame()\n\tquality_study_all<-data.frame()\n\n\ti<-1\n\tlist_plot<-list()\n\n\tfor (fsl in feature_select)\n\t{\n\t\tfor(mu in multi)\n\t\t{\n\t\t\tfor(an in anomalies)\n\t\t\t{\n\t\t\t\tfor(bc in box_cox)\n\t\t\t\t{\n\t\t\t\t\tfor(fst in feature_step)\n\t\t\t\t\t{\n\t\t\t\t\t\tstart.time <- Sys.time()\n\t\t\t\t\t\tdata<-prepare_study(data_study, data_test ,y_name ,fsl,mu,an,bc,stand,fst)\n\t\t\t\t\t\tend.time <- Sys.time()\n\t\t\t\t\t\ttime_prepare <- end.time - start.time\n\t\t\t\t\t\tif(!is.null(data))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tfor (m in models)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t#create name\n\t\t\t\t\t\t\t\tname_fsl<-ifelse(fsl,\"fsl\",\"nfsl\")\n\t\t\t\t\t\t\t\tname_mu<-ifelse(mu,\"mu\",\"nmu\")\n\t\t\t\t\t\t\t\tname_an<-ifelse(an,\"an\",\"nan\")\n\t\t\t\t\t\t\t\tname_bc<-ifelse(bc,\"bc\",\"nbc\")\n\t\t\t\t\t\t\t\tname_fst<-ifelse(fst,\"fst\",\"nfst\")\n\t\t\t\t\t\t\t\tname_st<-ifelse(stand,\"st\",\"nst\")\n\t\t\t\t\t\t\t\tname_full<-paste(m,name_fsl,name_mu,name_an,name_bc,name_fst,name_st,sep = \"_\")\n\t\t\t\t\t\t\t\tname_list<-c(name_list,name_full)\n\t\t\t\t\t\t\t\tprint(name_full)\n\n\t\t\t\t\t\t\t\t#model info\n\t\t\t\t\t\t\t\tstart.time <- Sys.time()\n\t\t\t\t\t\t\t\tmodel<-get_model(data$data_study,m)\n\t\t\t\t\t\t\t\tif(is_optimal_border)\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\toptimal_border<-optimal_border<-get_optimal_border(model, data$data_study, m, 'y')\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\toptimal_border<-0.5\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tend.time <- Sys.time()\n\t\t\t\t\t\t\t\ttime_model <- end.time - start.time\n\t\t\t\t\t\t\t\tmodel_info<-get_model_info(model,m)\n\t\t\t\t\t\t\t\tcount_features<-nrow(model_info[model_info[,2] < 0 | model_info[,2] > 0, ])\n\n\t\t\t\t\t\t\t\tmodel_info_all<-merge(model_info_all,model_info, by=c(\"Evidence\"),all = TRUE)\n\t\t\t\t\t\t\t\tnames(model_info_all)[ncol(model_info_all)]<-paste(names(model_info_all)[ncol(model_info_all)] , name_full ,sep = \"_\")\n\n\t\t\t\t\t\t\t\tmodel_info[model_info == 0] <- NA\n\t\t\t\t\t\t\t\tmodel_info[,-1]<-rank(-abs(model_info[,-1]),\"max\",na.last = \"keep\")\n\t\t\t\t\t\t\t\tmodel_info_all<-merge(model_info_all,model_info, by=c(\"Evidence\"),all = TRUE)\n\t\t\t\t\t\t\t\tnames(model_info_all)[ncol(model_info_all)]<-paste(\"rank\",names(model_info_all)[ncol(model_info_all)-1] , name_full ,sep = \"_\")\n\n\t\t\t\t\t\t\t\t#quality study\n\t\t\t\t\t\t\t\tquality_study<-get_quality_cv(data$data_study, n_folds=1, m, \"y\",optimal_border)\n\t\t\t\t\t\t\t\tquality_study_all<-rbind(quality_study_all,cbind(Full_Name=name_full,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Time_All=time_model+time_prepare,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Count_features=count_features,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t quality_study[names(quality_study)!='Plot_auc']))\n\t\t\t\t\t\t\t\t#quality cv\n\t\t\t\t\t\t\t\tif(n_folds > 1)\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tquality_cv<-get_quality_cv(data$data_study, n_folds=n_folds, m, \"y\",optimal_border)\n\t\t\t\t\t\t\t\t\tquality_cv_all<-rbind(quality_cv_all,cbind(Full_Name=name_full,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Time_All=time_model+time_prepare,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Count_features=count_features,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t quality_cv[names(quality_cv)!='Plot_auc']))\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t#quality test\n\t\t\t\t\t\t\t\tif(!is.null(data_test))\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tstart.time <- Sys.time()\n\t\t\t\t\t\t\t\t\tpredict_test<-get_prediction(model,data$data_test,m)\n\t\t\t\t\t\t\t\t\tend.time <- Sys.time()\n\t\t\t\t\t\t\t\t\ttime_predict <- end.time - start.time\n\t\t\t\t\t\t\t\t\tif(plot_test)\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tquality_test<-get_quality(data$data_test[,\"y\"],predict_test,optimal_border,plot_roc = TRUE)\n\t\t\t\t\t\t\t\t\t\tlist_plot[[i]]<-quality_test$Plot_auc\n\t\t\t\t\t\t\t\t\t\ti=i+1\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tquality_test<-get_quality(data$data_test[,\"y\"],predict_test,optimal_border,plot_roc = FALSE)\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tquality_test_all<-rbind(quality_test_all,cbind(Full_Name=name_full,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Time_All=time_predict,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Count_features=count_features,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t as.data.frame(quality_test[names(quality_test)!='Plot_auc'])))\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t}\n\n\tif(!is.null(data_test))\n\t{\n\t\tif(plot_test)\n\t\t{\n\t\t\tqual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]\n\t\t\tcolor_list = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))\n\t\t\tfor(l in 1:length(list_plot))\n\t\t\t{\n\t\t\t\t#plot roc\n\t\t\t\tif(l==1)\n\t\t\t\t{\n\t\t\t\t\tplot(list_plot[[l]],col = color_list[l],lwd = 2, main = \"ROC for test\")\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tplot(list_plot[[l]],col = color_list[l],lwd = 2,add = TRUE)\n\t\t\t\t}\n\t\t\t}\n\t\t\tlegend(\"bottom\", lwd = 5, col=color_list, name_list,cex=0.60,ncol=3)\n\t\t}\n\t}\n\treturn(list(quality_test=quality_test_all,\n\t\t\t\t\t\t\tquality_cv=quality_cv_all,\n\t\t\t\t\t\t\tquality_study=quality_study_all,\n\t\t\t\t\t\t\tmodel_info=model_info_all,\n\t\t\t\t\t\t\tlist_plot=list_plot\n\t))\n}\n\n\n#' Get optimal border\n#'\n#' Get optimal border for get quality\n#' @param model_obj is model derived from classification_go\n#' @param data data study\n#' @param model is name of model\n#' @param y_name is a name of oucome colum\n#' @return list\n#' @export\nget_optimal_border<-function(model_obj, data = NULL, model='glm', y_name = 'y')\n{\n\tpredictStudy<-get_prediction(model_obj,data,model,y_name = 'y')\n\toptimBorder<-optimalCutoff(actuals = data[,names(data) %in% y_name], predictedScores = predictStudy,optimiseFor =\"Both\" )\n\treturn(optimBorder)\n}\n\n\n#' Classification\n#'\n#' Start classification\n#' @param data_study is data study\n#' @param data_test is data test\n#' @param model is name of model\n#' @param y_name is a name of oucome colum\n#' @param feature_select is logical value is it necessary feature select\n#' @param n_folds is folds number\n#' @param is_optimal_border is logical value using of method for optimal boarding\n#' @param stand is logical value is it necessary feature standardization\n#' @param plot_roc is logical value is it necessary plot roc\n#' @param multi is logical value delete multicollinearity\n#' @param anomalies is logical value using of method for optimal boarding\n#' @param box_cox is logical value replace anomalies\n#' @param feature_step  is logical value select features by AUC\n#' @return list\n#' @export\nclassification_go<-function(data_study, data_test = NULL, model = 'glmnet', y_name = 'EndCat',is_optimal_border=FALSE,plot_roc=FALSE,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tfeature_select=TRUE,multi=TRUE,anomalies=TRUE,box_cox=TRUE,feature_step=TRUE,stand=FALSE,n_folds=0)\n{\n\tdata<-prepare_study(data_study, data_test ,y_name,feature_select,multi,anomalies,box_cox,stand,feature_step)\n\tresult_model<-get_model(data$data_study,model)\n\tprint(result_model)\n\tif(is_optimal_border)\n\t{\n\t\toptimal_border<-get_optimal_border(result_model, data$data_study, model, 'y')\n\t}\n\telse\n\t{\n\t\toptimal_border<-0.5\n\t}\n\n\n\tquality_cv<-NULL\n\tquality_study<-get_quality_cv(data$data_study, n_folds=1, model, \"y\",optimal_border)\n\tif(n_folds > 1)\n\t{\n\t\tquality_cv<-get_quality_cv(data$data_study, n_folds=n_folds, model, \"y\",optimal_border)\n\t}\n\tquality_test<-NULL\n\tif(!is.null(data_test))\n\t{\n\t\tpredict_test<-get_prediction(result_model,data$data_test,model)\n\t\tquality_test<-get_quality(data$data_test[,\"y\"],predict_test,optimal_border,plot_roc)\n\t}\n\tresult<-list( \"quality_cv\"=quality_cv,\n\t\t\t\t\t\t\t\t\"quality_test\"=quality_test,\n\t\t\t\t\t\t\t\t\"quality_study\"=quality_study,\n\t\t\t\t\t\t\t\t\"model\"=list(obj_model=result_model,model_type=model),\n\t\t\t\t\t\t\t\t\"prepare_info\"=data$prepare_info\n\t)\n\treturn(result)\n}\n\n#' Prediction\n#'\n#' Start prediction\n#' @param data_predict is data for prediction\n#' @param res_model is model derived from classification_go\n#' @return result vector with predict\n#' @export\nprediction_go<-function(data_predict, res_model)\n{\n\tcolumns_numbers<-which(colnames(data_predict) %in% res_model$prepare_info$significant_features)\n\tdata_predict<-data_predict[,columns_numbers]\n\n\tif(res_model$prepare_info$anomalies)\n\t{\n\t\tfor(i in 1:ncol(data_predict))\n\t\t{\n\t\t\tmax<-res_model$prepare_info$max_min_info$max[res_model$prepare_info$max_min_info$name==names(data_predict)[i]]\n\t\t\tmin<-res_model$prepare_info$max_min_info$min[res_model$prepare_info$max_min_info$name==names(data_predict)[i]]\n\t\t\tdata_predict[data_predict[,i]>max,i]<-max\n\t\t\tdata_predict[data_predict[,i]<min,i]<-min\n\t\t}\n\t}\n\tif(res_model$prepare_info$box_cox)\n\t{\n\t\tfor(i in 1:ncol(data_predict))\n\t\t{\n\t\t\tdata_predict[,i] <- box_cox(data_predict[,i],res_model$lamda_info$lamda[res_model$lamda_info$name==names(data_predict)[i]])\n\t\t}\n\t}\n\tif(res_model$prepare_info$stand)\n\t{\n\t\tdata_predict <- as.data.frame(scale(data_predict))\n\t}\n\tpredict<-get_prediction(res_model$model$obj_model,data_predict,res_model$model$model_type)\n\treturn(predict)\n}\n",
    "created" : 1561375184618.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "44|1|49|0|\n60|1|78|0|\n88|1|92|0|\n102|1|118|0|\n128|1|169|0|\n181|1|225|0|\n235|1|245|0|\n255|1|316|0|\n326|1|354|0|\n366|1|416|0|\n424|1|432|0|\n440|1|446|0|\n464|1|545|0|\n556|1|607|0|\n619|1|642|0|\n654|1|688|0|\n701|1|740|0|\n750|1|784|0|\n806|1|947|0|\n987|1|1020|0|\n1030|1|1057|0|\n",
    "hash" : "451776445",
    "id" : "701FADC6",
    "lastKnownWriteTime" : 1561392633,
    "last_content_update" : 1561392633821,
    "path" : "D:/R/BinClassComp/BinClassComp/R/classification.R",
    "project_path" : "R/classification.R",
    "properties" : {
        "source_window_id" : "",
        "tempName" : "Untitled1"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}